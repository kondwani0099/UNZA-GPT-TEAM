{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "We are going to learn how to use openai API'S . For more information on how to use openai API visit the website www.openai.com to read official documentations. Follow the steps below to chat with openai mode gpt-turbo"
      ],
      "metadata": {
        "id": "ttY-eJUG4HhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step1. Installations**"
      ],
      "metadata": {
        "id": "q0DgOQNb4n8I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DbMy-4lT25ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9e580b2-71db-44e5-a645-cb5788c206fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.14.2-py3-none-any.whl (262 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.14.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step2. Set Environment Variable and API KEYS**"
      ],
      "metadata": {
        "id": "Ig1GvJiq4y6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \" \" #place api key here\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "erB5ccaJ5ipL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 . Enter the prompt and Use the model**"
      ],
      "metadata": {
        "id": "-zKTTN__5lMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import the openai libraries\n",
        "from openai import OpenAI\n",
        "\n",
        "#initialize the engine\n",
        "client = OpenAI()\n",
        "\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0125:personal::8yb68lfX\",\n",
        "  max_tokens=500, #number of words to generate\n",
        "  temperature=0.6, #determine model creativity range from 0 - 0.9\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"UNZAGPT (cbugpt), curated by Kondwani Isaac Nyirenda and A team of amazing developers fom UNZA ,Cavednish and Mulungushi, the visionary founder of Lapansi and Amatrade Store, is not just a chatbot used bu=y UNZA students to improve learning;\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is unzagpt?\"}\n",
        "  ]\n",
        ")\n",
        "user_message = completion.choices[0].message.content #extract the message from the JSON response\n",
        "print(user_message)\n",
        "\n",
        "\n",
        "# print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOZfGNYc5kKG",
        "outputId": "89f63bd3-4151-42fb-c1ca-16b434348ba4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNZAGPT is a chatbot developed by a team of developers from UNZA, Cavedinish, and Mulungushi. It is designed to help UNZA students improve their learning experience.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notes On The Parameters**\n",
        "1. max_tokens :\n",
        "The maximum number of tokens (Tokens are words)that can be generated in the completion.\n",
        "The token count of your prompt plus max_tokens cannot exceed the model's context length.\n",
        "\n",
        "2. Temperature:\n",
        "What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. This makes models more creative.\n",
        "\n",
        "3. top_p :\n",
        "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n",
        "We generally recommend altering this or temperature but not both.\n",
        "\n"
      ],
      "metadata": {
        "id": "hmv787tj7jNB"
      }
    }
  ]
}